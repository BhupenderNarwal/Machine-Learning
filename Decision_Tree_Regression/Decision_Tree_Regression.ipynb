{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sra1IoWtTakL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree, metrics\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_excel('/content/CarSales.xlsx')"
      ],
      "metadata": {
        "id": "KIPDd28IUBBN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "OYTcImTAbhOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "df = df.applymap(str) # consider all the data as strings, I am not sure that this approach is appropiate but then I can skip imputing \n",
        "\n",
        "s = (df.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "label= df.copy()\n",
        "label_encoder = LabelEncoder()\n",
        "for col in object_cols:\n",
        "    label[col] = label_encoder.fit_transform(df[col])   \n",
        "\n",
        "missing = label.isnull().sum()\n",
        "print('missing values:',missing[missing > 0])\n",
        "print('the head:\\n',label.head())"
      ],
      "metadata": {
        "id": "JxopwGWPbkQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dftrain, dftest = train_test_split(label, test_size=0.2) # randomly split df to train/test data with 80/20 proportion\n",
        "\n",
        "#Let's check if prices distribution is same in test and train data\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1), dftrain['Price'].hist(bins=10)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,2),dftest['Price'].hist(bins=10)"
      ],
      "metadata": {
        "id": "W6DpMlyIbnmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "features = list(label.columns)\n",
        "features.remove('Price') \n",
        "train_y = dftrain['Price'] \n",
        "train_x = dftrain[features] \n",
        "test_x=dftest[features] \n",
        "test_y=dftest['Price'] \n",
        "model = DecisionTreeRegressor(random_state=1)\n",
        "model.fit(train_x, train_y)\n",
        "predicted_prices = model.predict(test_x)\n",
        "predicted_prices=pd.DataFrame(predicted_prices)"
      ],
      "metadata": {
        "id": "68W9-dWObqoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate mae \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mae = mean_absolute_error(predicted_prices, test_y)\n",
        "print('mean absolute error: ',mae)\n",
        "print('mean price in df:', label['Price'].mean(), '\\nmae/mean, %:',100*mae/label['Price'].mean())"
      ],
      "metadata": {
        "id": "0ig85t3pbuJ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}